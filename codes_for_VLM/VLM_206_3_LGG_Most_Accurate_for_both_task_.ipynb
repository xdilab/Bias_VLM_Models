{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da7871f-507b-48bc-b211-35f8f6c313dc",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5f544ace1dfa49519a0147fc7e465cba",
            "0126dfd74d1a41fb996002fe1489ff70"
          ]
        },
        "id": "4da7871f-507b-48bc-b211-35f8f6c313dc",
        "outputId": "b78e293a-d16c-40df-cb72-f5ac9f6b22d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Gathering and splitting data...\n",
            "\n",
            "Step 2: Setting up multi-task model and processor...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f544ace1dfa49519a0147fc7e465cba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LoRA target modules: ['down_proj', 'gate_proj', 'k_proj', 'linear_1', 'linear_2', 'o_proj', 'out_proj', 'q_proj', 'up_proj', 'v_proj']\n",
            "trainable params: 86,671,360 || all params: 7,150,098,432 || trainable%: 1.2122\n",
            "\n",
            "Step 3: Preparing DataLoaders...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Dataset with Tumor/No-Tumor Logic: 100%|█| 2488/2488 [00:01<00:00, 13\n",
            "Processing Dataset with Tumor/No-Tumor Logic: 100%|█| 623/623 [00:00<00:00, 1787\n",
            "Processing Dataset with Tumor/No-Tumor Logic: 100%|█| 778/778 [00:00<00:00, 1659\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total samples loaded: 2432 training, 607 validation, and 763 test.\n",
            "\n",
            "Step 4: Starting multi-task fine-tuning...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1: 100%|█████████████████████| 1216/1216 [12:32<00:00,  1.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 Avg Combined Loss -> 0.8642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:09<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     82.54%\n",
            "  - Perplexity (teacher-forced): 1.0272\n",
            "  - Segmentation IoU:            0.0550\n",
            "  - Avg Segmentation Loss:       0.9734\n",
            "----------------------------------------\n",
            "  -> New best validation metric (88.04). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2: 100%|█████████████████████| 1216/1216 [12:09<00:00,  1.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Avg Combined Loss -> 0.4933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:09<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     81.38%\n",
            "  - Perplexity (teacher-forced): 1.0203\n",
            "  - Segmentation IoU:            0.7626\n",
            "  - Avg Segmentation Loss:       0.9240\n",
            "----------------------------------------\n",
            "  -> New best validation metric (157.65). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3: 100%|█████████████████████| 1216/1216 [12:06<00:00,  1.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 Avg Combined Loss -> 0.4573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:09<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     87.15%\n",
            "  - Perplexity (teacher-forced): 1.0180\n",
            "  - Segmentation IoU:            0.8607\n",
            "  - Avg Segmentation Loss:       0.8414\n",
            "----------------------------------------\n",
            "  -> New best validation metric (173.22). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4: 100%|█████████████████████| 1216/1216 [12:05<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 Avg Combined Loss -> 0.4110\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:09<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     83.69%\n",
            "  - Perplexity (teacher-forced): 1.0281\n",
            "  - Segmentation IoU:            0.8975\n",
            "  - Avg Segmentation Loss:       0.7527\n",
            "----------------------------------------\n",
            "  -> New best validation metric (173.44). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5: 100%|█████████████████████| 1216/1216 [11:57<00:00,  1.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 Avg Combined Loss -> 0.3728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:08<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     90.94%\n",
            "  - Perplexity (teacher-forced): 1.0187\n",
            "  - Segmentation IoU:            0.9181\n",
            "  - Avg Segmentation Loss:       0.6826\n",
            "----------------------------------------\n",
            "  -> New best validation metric (182.75). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6: 100%|█████████████████████| 1216/1216 [11:59<00:00,  1.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 Avg Combined Loss -> 0.3456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:09<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     91.93%\n",
            "  - Perplexity (teacher-forced): 1.0137\n",
            "  - Segmentation IoU:            0.9290\n",
            "  - Avg Segmentation Loss:       0.6406\n",
            "----------------------------------------\n",
            "  -> New best validation metric (184.83). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 7: 100%|█████████████████████| 1216/1216 [11:53<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7 Avg Combined Loss -> 0.3242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:09<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     91.93%\n",
            "  - Perplexity (teacher-forced): 1.0153\n",
            "  - Segmentation IoU:            0.9403\n",
            "  - Avg Segmentation Loss:       0.6075\n",
            "----------------------------------------\n",
            "  -> New best validation metric (185.96). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 8: 100%|█████████████████████| 1216/1216 [11:52<00:00,  1.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8 Avg Combined Loss -> 0.3054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:08<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     91.93%\n",
            "  - Perplexity (teacher-forced): 1.0155\n",
            "  - Segmentation IoU:            0.9393\n",
            "  - Avg Segmentation Loss:       0.5672\n",
            "----------------------------------------\n",
            "  -> No improvement for 1 epoch(s).\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 9: 100%|█████████████████████| 1216/1216 [11:45<00:00,  1.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9 Avg Combined Loss -> 0.2984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:08<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     93.25%\n",
            "  - Perplexity (teacher-forced): 1.0225\n",
            "  - Segmentation IoU:            0.9376\n",
            "  - Avg Segmentation Loss:       0.5701\n",
            "----------------------------------------\n",
            "  -> New best validation metric (187.01). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 10: 100%|████████████████████| 1216/1216 [11:44<00:00,  1.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10 Avg Combined Loss -> 0.2858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:09<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     92.59%\n",
            "  - Perplexity (teacher-forced): 1.0237\n",
            "  - Segmentation IoU:            0.9457\n",
            "  - Avg Segmentation Loss:       0.5510\n",
            "----------------------------------------\n",
            "  -> New best validation metric (187.15). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 11: 100%|████████████████████| 1216/1216 [11:44<00:00,  1.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11 Avg Combined Loss -> 0.2822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:08<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     91.60%\n",
            "  - Perplexity (teacher-forced): 1.0299\n",
            "  - Segmentation IoU:            0.9475\n",
            "  - Avg Segmentation Loss:       0.5436\n",
            "----------------------------------------\n",
            "  -> No improvement for 1 epoch(s).\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 12: 100%|████████████████████| 1216/1216 [11:41<00:00,  1.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12 Avg Combined Loss -> 0.2774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:08<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     94.07%\n",
            "  - Perplexity (teacher-forced): 1.0207\n",
            "  - Segmentation IoU:            0.9382\n",
            "  - Avg Segmentation Loss:       0.5493\n",
            "----------------------------------------\n",
            "  -> New best validation metric (187.89). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 13: 100%|████████████████████| 1216/1216 [11:39<00:00,  1.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 13 Avg Combined Loss -> 0.2702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:08<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     93.08%\n",
            "  - Perplexity (teacher-forced): 1.0282\n",
            "  - Segmentation IoU:            0.9397\n",
            "  - Avg Segmentation Loss:       0.5432\n",
            "----------------------------------------\n",
            "  -> No improvement for 1 epoch(s).\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 14: 100%|████████████████████| 1216/1216 [11:37<00:00,  1.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 14 Avg Combined Loss -> 0.2656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:08<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     93.57%\n",
            "  - Perplexity (teacher-forced): 1.0318\n",
            "  - Segmentation IoU:            0.9439\n",
            "  - Avg Segmentation Loss:       0.5344\n",
            "----------------------------------------\n",
            "  -> New best validation metric (187.96). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 15: 100%|████████████████████| 1216/1216 [11:32<00:00,  1.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 15 Avg Combined Loss -> 0.2621\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:09<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     90.94%\n",
            "  - Perplexity (teacher-forced): 1.0602\n",
            "  - Segmentation IoU:            0.9459\n",
            "  - Avg Segmentation Loss:       0.5305\n",
            "----------------------------------------\n",
            "  -> No improvement for 1 epoch(s).\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 16: 100%|████████████████████| 1216/1216 [11:32<00:00,  1.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 16 Avg Combined Loss -> 0.2626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:07<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     93.41%\n",
            "  - Perplexity (teacher-forced): 1.0363\n",
            "  - Segmentation IoU:            0.9441\n",
            "  - Avg Segmentation Loss:       0.5307\n",
            "----------------------------------------\n",
            "  -> No improvement for 2 epoch(s).\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 17: 100%|████████████████████| 1216/1216 [11:31<00:00,  1.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 17 Avg Combined Loss -> 0.2643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:07<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     93.57%\n",
            "  - Perplexity (teacher-forced): 1.0344\n",
            "  - Segmentation IoU:            0.9481\n",
            "  - Avg Segmentation Loss:       0.5244\n",
            "----------------------------------------\n",
            "  -> New best validation metric (188.38). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 18: 100%|████████████████████| 1216/1216 [11:31<00:00,  1.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 18 Avg Combined Loss -> 0.2618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:07<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     94.89%\n",
            "  - Perplexity (teacher-forced): 1.0387\n",
            "  - Segmentation IoU:            0.9476\n",
            "  - Avg Segmentation Loss:       0.5233\n",
            "----------------------------------------\n",
            "  -> New best validation metric (189.65). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 19: 100%|████████████████████| 1216/1216 [11:26<00:00,  1.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 19 Avg Combined Loss -> 0.2599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:07<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     93.90%\n",
            "  - Perplexity (teacher-forced): 1.0519\n",
            "  - Segmentation IoU:            0.9491\n",
            "  - Avg Segmentation Loss:       0.5198\n",
            "----------------------------------------\n",
            "  -> No improvement for 1 epoch(s).\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 20: 100%|████████████████████| 1216/1216 [11:26<00:00,  1.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 20 Avg Combined Loss -> 0.2618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:08<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     94.89%\n",
            "  - Perplexity (teacher-forced): 1.0434\n",
            "  - Segmentation IoU:            0.9464\n",
            "  - Avg Segmentation Loss:       0.5256\n",
            "----------------------------------------\n",
            "  -> No improvement for 2 epoch(s).\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 21: 100%|████████████████████| 1216/1216 [11:24<00:00,  1.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 21 Avg Combined Loss -> 0.2589\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:08<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     94.23%\n",
            "  - Perplexity (teacher-forced): 1.0517\n",
            "  - Segmentation IoU:            0.9447\n",
            "  - Avg Segmentation Loss:       0.5266\n",
            "----------------------------------------\n",
            "  -> No improvement for 3 epoch(s).\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 22: 100%|████████████████████| 1216/1216 [11:23<00:00,  1.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 22 Avg Combined Loss -> 0.2541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:06<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     93.41%\n",
            "  - Perplexity (teacher-forced): 1.0474\n",
            "  - Segmentation IoU:            0.9465\n",
            "  - Avg Segmentation Loss:       0.5243\n",
            "----------------------------------------\n",
            "  -> No improvement for 4 epoch(s).\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 23: 100%|████████████████████| 1216/1216 [11:23<00:00,  1.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 23 Avg Combined Loss -> 0.2538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:07<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     94.89%\n",
            "  - Perplexity (teacher-forced): 1.0461\n",
            "  - Segmentation IoU:            0.9504\n",
            "  - Avg Segmentation Loss:       0.5192\n",
            "----------------------------------------\n",
            "  -> New best validation metric (189.93). Saving model...\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 24: 100%|████████████████████| 1216/1216 [11:25<00:00,  1.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 24 Avg Combined Loss -> 0.2527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:07<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     94.73%\n",
            "  - Perplexity (teacher-forced): 1.0487\n",
            "  - Segmentation IoU:            0.9459\n",
            "  - Avg Segmentation Loss:       0.5254\n",
            "----------------------------------------\n",
            "  -> No improvement for 1 epoch(s).\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 25: 100%|████████████████████| 1216/1216 [11:24<00:00,  1.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 25 Avg Combined Loss -> 0.2605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation Set Eval: 100%|████████████████████| 304/304 [04:07<00:00,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Validation Set Eval ---\n",
            "  - VLM Grade Accuracy (QA):     94.89%\n",
            "  - Perplexity (teacher-forced): 1.0480\n",
            "  - Segmentation IoU:            0.9487\n",
            "  - Avg Segmentation Loss:       0.5213\n",
            "----------------------------------------\n",
            "  -> No improvement for 2 epoch(s).\n",
            "================================================================================\n",
            "\n",
            "Step 5: Loading best model for final evaluation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0126dfd74d1a41fb996002fe1489ff70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Final Test Evaluation: 100%|██████████████████| 382/382 [05:13<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for Final Test Evaluation ---\n",
            "  - VLM Grade Accuracy (QA):     92.66%\n",
            "  - Perplexity (teacher-forced): 1.0542\n",
            "  - Segmentation IoU:            0.9393\n",
            "  - Avg Segmentation Loss:       0.4721\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "import re\n",
        "import random\n",
        "import logging\n",
        "import warnings\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "from transformers import (\n",
        "    AutoProcessor,\n",
        "    LlavaForConditionalGeneration,\n",
        "    CLIPVisionModel,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "\n",
        "class JaccardLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super(JaccardLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "\n",
        "        y_pred_probs = torch.sigmoid(y_pred)\n",
        "\n",
        "\n",
        "        y_pred_flat = y_pred_probs.view(-1)\n",
        "        y_true_flat = y_true.view(-1)\n",
        "\n",
        "\n",
        "        intersection = (y_pred_flat * y_true_flat).sum()\n",
        "        total = (y_pred_flat + y_true_flat).sum()\n",
        "        union = total - intersection\n",
        "\n",
        "\n",
        "        iou = (intersection + self.smooth) / (union + self.smooth)\n",
        "        return 1 - iou\n",
        "\n",
        "\n",
        "#  Dataset now handles cases WITH and WITHOUT tumors\n",
        "\n",
        "class VLM_QASegDataset(Dataset):\n",
        "    def __init__(self, image_paths: List[str], metadata_df: pd.DataFrame, is_train: bool = True):\n",
        "        self.image_paths: List[str] = []\n",
        "        self.mask_paths: List[str] = []\n",
        "        self.questions: List[str] = []\n",
        "        self.answers: List[str] = []\n",
        "        self.is_train = is_train\n",
        "\n",
        "\n",
        "        if self.is_train:\n",
        "            self.image_transform = transforms.Compose([\n",
        "                transforms.Resize((336, 336)),\n",
        "                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "            ])\n",
        "        else:\n",
        "            self.image_transform = transforms.Compose([\n",
        "                transforms.Resize((336, 336)),\n",
        "            ])\n",
        "\n",
        "        self.mask_transform = transforms.Compose([\n",
        "            transforms.Resize((336, 336), interpolation=transforms.InterpolationMode.NEAREST),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        mdx = metadata_df.set_index(\"Patient\")\n",
        "        for img_path in tqdm(image_paths, desc=\"Processing Dataset with Tumor/No-Tumor Logic\"):\n",
        "            mask_path = img_path.replace(\".tif\", \"_mask.tif\")\n",
        "            if not os.path.exists(mask_path):\n",
        "                continue\n",
        "\n",
        "            pid_folder = os.path.basename(os.path.dirname(img_path))\n",
        "            pid_key = \"_\".join(pid_folder.split(\"_\")[0:3])\n",
        "            if pid_key in mdx.index:\n",
        "                row = mdx.loc[[pid_key]].iloc[0]\n",
        "                grade = row.get(\"neoplasm_histologic_grade\")\n",
        "                if pd.notna(grade) and int(grade) in [1, 2]:\n",
        "\n",
        "                    mask_image = Image.open(mask_path)\n",
        "                    has_tumor = np.sum(np.array(mask_image)) > 0\n",
        "\n",
        "\n",
        "                    q = \"Analyze the provided medical image. Is a tumor visible? If so, identify it and determine its histologic grade: one or two.\"\n",
        "\n",
        "                    if has_tumor:\n",
        "                        # Case 1: Tumor is present in the slice\n",
        "                        grade_str = \"two\" if int(grade) == 2 else \"one\"\n",
        "                        a = f\"A tumor is visible, and its grade is {grade_str}.\"\n",
        "                    else:\n",
        "                        # Case 2: No tumor in this slice. Teach the model to state this explicitly.\n",
        "                        a = \"There is no tumor visible in this image.\"\n",
        "\n",
        "\n",
        "                    self.image_paths.append(img_path)\n",
        "                    self.mask_paths.append(mask_path)\n",
        "                    self.questions.append(q)\n",
        "                    self.answers.append(a)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        mask = Image.open(self.mask_paths[idx]).convert(\"L\")\n",
        "\n",
        "        image_np = np.array(image)\n",
        "        mask_np = (np.array(mask) > 0).astype(np.uint8)\n",
        "        contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        cv2.drawContours(image_np, contours, -1, (0, 255, 255), thickness=2)\n",
        "        image = Image.fromarray(image_np)\n",
        "\n",
        "\n",
        "        image = self.image_transform(image)\n",
        "        mask_tensor = self.mask_transform(mask)\n",
        "        mask_tensor = (mask_tensor > 0).float()\n",
        "\n",
        "        return image, mask_tensor, self.questions[idx], self.answers[idx]\n",
        "\n",
        "\n",
        "def vlm_collate_fn_for_training(batch):\n",
        "    images, masks, questions, answers = zip(*batch)\n",
        "    masks_tensor = torch.stack(masks)\n",
        "    return list(images), masks_tensor, list(questions), list(answers)\n",
        "\n",
        "def vlm_collate_fn_for_evaluation(batch):\n",
        "    images, masks, questions, answers = zip(*batch)\n",
        "    masks_tensor = torch.stack(masks)\n",
        "    return list(images), masks_tensor, list(questions), list(answers)\n",
        "\n",
        "def build_training_batch_cpu_main(images, masks, questions, answers, processor: AutoProcessor):\n",
        "    prompts = [f\"USER: <image>\\n{q}\\nASSISTANT:\" for q in questions]\n",
        "    full_texts = [\n",
        "        f\"USER: <image>\\n{q}\\nASSISTANT: {a}{processor.tokenizer.eos_token}\"\n",
        "        for q, a in zip(questions, answers)\n",
        "    ]\n",
        "    toks_prompt = processor(text=prompts, images=images, return_tensors=\"pt\", padding=True)\n",
        "    toks_full = processor(text=full_texts, images=images, return_tensors=\"pt\", padding=True)\n",
        "    labels = toks_full.input_ids.clone()\n",
        "    prompt_lens = torch.sum(toks_prompt.attention_mask, dim=1)\n",
        "    for i in range(labels.size(0)):\n",
        "        labels[i, : prompt_lens[i]] = -100\n",
        "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
        "    return {\n",
        "        \"input_ids\": toks_full.input_ids, \"pixel_values\": toks_full.pixel_values,\n",
        "        \"attention_mask\": toks_full.attention_mask, \"labels\": labels, \"seg_masks_gt\": masks,\n",
        "    }\n",
        "\n",
        "\n",
        "class LlavaWithSegmentationHead(nn.Module):\n",
        "    def __init__(self, llava_model):\n",
        "        super().__init__()\n",
        "        self.llava = llava_model\n",
        "        self.vision_tower = self.llava.vision_tower\n",
        "        self.seg_model = smp.DeepLabV3Plus(\n",
        "            encoder_name=\"resnet34\", encoder_weights=None, in_channels=3, classes=1,\n",
        "        )\n",
        "        smp_encoder_channels = self.seg_model.encoder.out_channels\n",
        "        self.projection = nn.ModuleList([\n",
        "            nn.Conv2d(1024, smp_encoder_channels[1], kernel_size=1),\n",
        "            nn.Conv2d(1024, smp_encoder_channels[2], kernel_size=1),\n",
        "            nn.Conv2d(1024, smp_encoder_channels[3], kernel_size=1),\n",
        "            nn.Conv2d(1024, smp_encoder_channels[4], kernel_size=1),\n",
        "            nn.Conv2d(1024, smp_encoder_channels[5], kernel_size=1),\n",
        "        ])\n",
        "\n",
        "    def forward(self, input_ids, pixel_values, attention_mask, labels=None, **kwargs):\n",
        "        image_features = self.vision_tower(pixel_values, output_hidden_states=True)\n",
        "        image_features_grid = image_features.hidden_states[-1][:, 1:, :]\n",
        "        batch_size, patch_grid_size_sq, hidden_size = image_features_grid.shape\n",
        "        patch_grid_size = int(math.sqrt(patch_grid_size_sq))\n",
        "        seg_features = image_features_grid.reshape(batch_size, patch_grid_size, patch_grid_size, hidden_size).permute(0, 3, 1, 2).contiguous()\n",
        "        projected_features = [proj(seg_features) for proj in self.projection]\n",
        "        scaled_projected_features = list(projected_features)\n",
        "        scaled_projected_features[1] = F.interpolate(scaled_projected_features[1], scale_factor=4, mode='bilinear', align_corners=False)\n",
        "        decoder_features = [None] + scaled_projected_features\n",
        "        decoder_output = self.seg_model.decoder(decoder_features)\n",
        "        seg_logits = self.seg_model.segmentation_head(decoder_output)\n",
        "        seg_logits = F.interpolate(seg_logits, size=(336, 336), mode='bilinear', align_corners=False)\n",
        "        vqa_output = self.llava(input_ids=input_ids, pixel_values=pixel_values, attention_mask=attention_mask, labels=labels, return_dict=True)\n",
        "        return {\"vqa_loss\": vqa_output.loss, \"vqa_logits\": vqa_output.logits, \"seg_logits\": seg_logits.squeeze(1)}\n",
        "\n",
        "\n",
        "# Evaluation function to handle \"no tumor\" case\n",
        "\n",
        "def compute_iou(pred_mask, true_mask, threshold=0.5):\n",
        "    with torch.no_grad():\n",
        "        pred_mask = (torch.sigmoid(pred_mask) > threshold).float()\n",
        "        true_mask = true_mask.float()\n",
        "        intersection = (pred_mask * true_mask).sum(dim=(1, 2))\n",
        "        union = pred_mask.sum(dim=(1, 2)) + true_mask.sum(dim=(1, 2)) - intersection\n",
        "        iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "        return iou.mean().item()\n",
        "\n",
        "def run_evaluation(model, processor, data_loader: DataLoader, device, description=\"Evaluating\"):\n",
        "    model.eval()\n",
        "    total_samples, vlm_correct, total_loss_count = 0, 0, 0\n",
        "    total_vqa_loss_sum, total_seg_loss_sum, total_iou = 0.0, 0.0, 0.0\n",
        "    seg_loss_fn = JaccardLoss().to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=description):\n",
        "            images, masks_gt, questions, answers = batch\n",
        "            masks_gt = masks_gt.to(device)\n",
        "            prompts = [f\"USER: <image>\\n{q}\\nASSISTANT:\" for q in questions]\n",
        "\n",
        "            with autocast():\n",
        "                gen_inputs = processor(text=prompts, images=images, return_tensors=\"pt\", padding=True).to(device)\n",
        "                generated_ids = model.llava.generate(**gen_inputs, max_new_tokens=25, pad_token_id=processor.tokenizer.pad_token_id)\n",
        "            decoded = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "            for i in range(len(decoded)):\n",
        "                pred_span = decoded[i].split(\"ASSISTANT:\")[-1].strip().lower()\n",
        "                true_span = answers[i].lower()\n",
        "\n",
        "                is_true_no_tumor = \"no tumor\" in true_span\n",
        "                is_pred_no_tumor = \"no tumor\" in pred_span\n",
        "\n",
        "                want_two = \"two\" in true_span\n",
        "                has_one = \"one\" in pred_span or \"1\" in pred_span\n",
        "                has_two = \"two\" in pred_span or \"2\" in pred_span\n",
        "\n",
        "                ok = False\n",
        "                if is_true_no_tumor:\n",
        "                    if is_pred_no_tumor and not has_one and not has_two:\n",
        "                        ok = True\n",
        "                else:\n",
        "                    grade_ok = (want_two and has_two and not has_one) or ((not want_two) and has_one and not has_two)\n",
        "                    if grade_ok and not is_pred_no_tumor:\n",
        "                        ok = True\n",
        "\n",
        "                if ok:\n",
        "                    vlm_correct += 1\n",
        "\n",
        "\n",
        "            batch_cpu = build_training_batch_cpu_main(images, masks_gt.cpu(), questions, answers, processor)\n",
        "            batch_gpu = {k: v.to(device) if torch.is_tensor(v) else v for k, v in batch_cpu.items()}\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(**batch_gpu)\n",
        "                vqa_loss, seg_logits = outputs[\"vqa_loss\"], outputs[\"seg_logits\"]\n",
        "                seg_loss = seg_loss_fn(seg_logits, batch_gpu[\"seg_masks_gt\"].squeeze(1))\n",
        "\n",
        "            if vqa_loss is not None: total_vqa_loss_sum += vqa_loss.item()\n",
        "            if seg_loss is not None: total_seg_loss_sum += seg_loss.item()\n",
        "            total_loss_count += 1\n",
        "            total_iou += compute_iou(seg_logits, batch_gpu[\"seg_masks_gt\"].squeeze(1))\n",
        "            total_samples += len(answers)\n",
        "\n",
        "    vlm_acc = (vlm_correct / total_samples) * 100 if total_samples else 0.0\n",
        "    avg_vqa_loss = total_vqa_loss_sum / total_loss_count if total_loss_count else float(\"inf\")\n",
        "    avg_seg_loss = total_seg_loss_sum / total_loss_count if total_loss_count else float(\"inf\")\n",
        "    avg_iou = total_iou / total_loss_count if total_loss_count else 0.0\n",
        "    ppl = math.exp(avg_vqa_loss) if avg_vqa_loss < 50 else float(\"inf\")\n",
        "\n",
        "    print(f\"\\n--- Results for {description} ---\")\n",
        "    print(f\"  - VLM Grade Accuracy (QA):     {vlm_acc:.2f}%\")\n",
        "    print(f\"  - Perplexity (teacher-forced): {ppl:.4f}\")\n",
        "    print(f\"  - Segmentation IoU:            {avg_iou:.4f}\")\n",
        "    print(f\"  - Avg Segmentation Loss:       {avg_seg_loss:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "    return vlm_acc, avg_iou\n",
        "\n",
        "def discover_lora_targets(llava_model, include_vision: bool = True) -> List[str]:\n",
        "\n",
        "    text_keys = {\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"}\n",
        "    projector_keys = {\"multi_modal_projector\"}\n",
        "    vision_keys = {\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"}\n",
        "    target_modules: set[str] = set()\n",
        "    for name, module in llava_model.named_modules():\n",
        "        if any(k in name for k in text_keys) and \"language_model\" in name:\n",
        "            target_modules.add(name.split(\".\")[-1])\n",
        "        if any(k in name for k in projector_keys):\n",
        "            if hasattr(module, \"weight\") and getattr(module, \"weight\", None) is not None:\n",
        "                target_modules.add(name.split(\".\")[-1])\n",
        "        if include_vision and (\"vision_tower\" in name) and any(k in name for k in vision_keys):\n",
        "            target_modules.add(name.split(\".\")[-1])\n",
        "    return sorted(list(target_modules))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    config = {\n",
        "        \"device\": \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
        "        \"base_path\": \"/home/ealam/Downloads/LGG dataset Cameron/lgg-mri-segmentation/kaggle_3m\",\n",
        "        \"local_llava_path\": \"/home/ealam/Desktop/llava-1.5-7b-local\",\n",
        "        \"save_path\": \"./llava-lora-multitask-with-negatives\",\n",
        "        \"csv_path\": \"/home/ealam/Downloads/LGG dataset Cameron/lgg-mri-segmentation/kaggle_3m/data.csv\",\n",
        "        \"learning_rate\": 1e-5,\n",
        "        \"batch_size\": 2,\n",
        "        \"num_epochs\": 25,\n",
        "        \"early_stopping_patience\": 5,\n",
        "        \"seed\": 42,\n",
        "        \"include_vision_lora\": True,\n",
        "\n",
        "        \"seg_loss_weight\": 0.5,\n",
        "        \"num_workers\": 4,\n",
        "        \"grad_clip_val\": 1.0,\n",
        "    }\n",
        "\n",
        "    torch.manual_seed(config[\"seed\"])\n",
        "    np.random.seed(config[\"seed\"])\n",
        "    random.seed(config[\"seed\"])\n",
        "\n",
        "    print(\"Step 1: Gathering and splitting data...\")\n",
        "    all_image_paths = [p.replace(\"_mask.tif\", \".tif\") for p in glob.glob(os.path.join(config[\"base_path\"], \"*\", \"*_mask.tif\"))]\n",
        "    all_image_paths = [p for p in all_image_paths if os.path.exists(p)]\n",
        "    usable_paths, _ = train_test_split(all_image_paths, test_size=0.01, random_state=config[\"seed\"])\n",
        "    train_val_paths, test_paths = train_test_split(usable_paths, test_size=0.20, random_state=config[\"seed\"])\n",
        "    train_paths, val_paths = train_test_split(train_val_paths, test_size=0.20, random_state=config[\"seed\"])\n",
        "\n",
        "    print(\"\\nStep 2: Setting up multi-task model and processor...\")\n",
        "    DEVICE = config[\"device\"]\n",
        "    base_model = LlavaForConditionalGeneration.from_pretrained(config[\"local_llava_path\"], torch_dtype=torch.float16, low_cpu_mem_usage=True)\n",
        "    processor = AutoProcessor.from_pretrained(config[\"local_llava_path\"])\n",
        "    if processor.tokenizer.pad_token is None:\n",
        "        processor.tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "        base_model.resize_token_embeddings(len(processor.tokenizer))\n",
        "\n",
        "    target_modules = discover_lora_targets(base_model, include_vision=config[\"include_vision_lora\"])\n",
        "    print(\"LoRA target modules:\", target_modules)\n",
        "    lora_cfg = LoraConfig(r=32, lora_alpha=64, target_modules=target_modules, lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\")\n",
        "    peft_model = get_peft_model(base_model, lora_cfg)\n",
        "    multitask_model = LlavaWithSegmentationHead(peft_model).to(DEVICE)\n",
        "    peft_model.print_trainable_parameters()\n",
        "\n",
        "    print(\"\\nStep 3: Preparing DataLoaders...\")\n",
        "    metadata_df = pd.read_csv(config[\"csv_path\"])\n",
        "    train_ds = VLM_QASegDataset(train_paths, metadata_df, is_train=True)\n",
        "    val_ds = VLM_QASegDataset(val_paths, metadata_df, is_train=False)\n",
        "    test_ds = VLM_QASegDataset(test_paths, metadata_df, is_train=False)\n",
        "    print(f\"\\nTotal samples loaded: {len(train_ds)} training, {len(val_ds)} validation, and {len(test_ds)} test.\")\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=config[\"batch_size\"], shuffle=True, num_workers=config[\"num_workers\"], collate_fn=vlm_collate_fn_for_training)\n",
        "    val_loader = DataLoader(val_ds, batch_size=config[\"batch_size\"], shuffle=False, num_workers=config[\"num_workers\"], collate_fn=vlm_collate_fn_for_evaluation)\n",
        "    test_loader = DataLoader(test_ds, batch_size=config[\"batch_size\"], shuffle=False, num_workers=config[\"num_workers\"], collate_fn=vlm_collate_fn_for_evaluation)\n",
        "\n",
        "    print(\"\\nStep 4: Starting multi-task fine-tuning...\")\n",
        "    trainable_params = [p for p in multitask_model.parameters() if p.requires_grad]\n",
        "    optimizer = AdamW(trainable_params, lr=config[\"learning_rate\"])\n",
        "    scaler = GradScaler()\n",
        "    seg_loss_fn = JaccardLoss().to(DEVICE)\n",
        "\n",
        "    num_training_steps = len(train_loader) * config[\"num_epochs\"]\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * num_training_steps), num_training_steps=num_training_steps)\n",
        "\n",
        "    best_val_metric, patience = 0.0, 0\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        multitask_model.train()\n",
        "        total_loss = 0.0\n",
        "        for images, masks, questions, answers in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "            batch_cpu = build_training_batch_cpu_main(images, masks, questions, answers, processor)\n",
        "            batch_gpu = {k: v.to(DEVICE) if torch.is_tensor(v) else v for k, v in batch_cpu.items()}\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with autocast():\n",
        "                outputs = multitask_model(**batch_gpu)\n",
        "                vqa_loss, seg_logits = outputs[\"vqa_loss\"], outputs[\"seg_logits\"]\n",
        "                seg_loss = seg_loss_fn(seg_logits, batch_gpu[\"seg_masks_gt\"].squeeze(1))\n",
        "                combined_loss = vqa_loss + config[\"seg_loss_weight\"] * seg_loss\n",
        "            scaler.scale(combined_loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(trainable_params, config[\"grad_clip_val\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            total_loss += combined_loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"\\nEpoch {epoch+1} Avg Combined Loss -> {avg_loss:.4f}\")\n",
        "\n",
        "        val_acc, val_iou = run_evaluation(multitask_model, processor, val_loader, DEVICE, \"Validation Set Eval\")\n",
        "        current_metric = val_acc + (val_iou * 100)\n",
        "\n",
        "        if current_metric > best_val_metric:\n",
        "            print(f\"  -> New best validation metric ({current_metric:.2f}). Saving model...\")\n",
        "            best_val_metric = current_metric\n",
        "            patience = 0\n",
        "            save_dir = config[\"save_path\"]\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            torch.save(multitask_model.seg_model.state_dict(), os.path.join(save_dir, \"seg_model.pth\"))\n",
        "            torch.save(multitask_model.projection.state_dict(), os.path.join(save_dir, \"projection.pth\"))\n",
        "            multitask_model.llava.save_pretrained(os.path.join(save_dir, \"llava_lora\"))\n",
        "            processor.save_pretrained(os.path.join(save_dir, \"processor\"))\n",
        "        else:\n",
        "            patience += 1\n",
        "            print(f\"  -> No improvement for {patience} epoch(s).\")\n",
        "            if patience >= config[\"early_stopping_patience\"]:\n",
        "                print(\"\\n--- Early stopping triggered. ---\")\n",
        "                break\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    print(\"\\nStep 5: Loading best model for final evaluation...\")\n",
        "    save_path = config[\"save_path\"]\n",
        "    if os.path.exists(os.path.join(save_path, \"seg_model.pth\")):\n",
        "        final_base_model = LlavaForConditionalGeneration.from_pretrained(config[\"local_llava_path\"], torch_dtype=torch.float16)\n",
        "        final_peft_model = PeftModel.from_pretrained(final_base_model, os.path.join(save_path, \"llava_lora\"))\n",
        "        final_multitask_model = LlavaWithSegmentationHead(final_peft_model).to(DEVICE)\n",
        "        final_multitask_model.seg_model.load_state_dict(torch.load(os.path.join(save_path, \"seg_model.pth\")))\n",
        "        final_multitask_model.projection.load_state_dict(torch.load(os.path.join(save_path, \"projection.pth\")))\n",
        "        final_processor = AutoProcessor.from_pretrained(os.path.join(save_path, \"processor\"))\n",
        "\n",
        "        run_evaluation(final_multitask_model, final_processor, test_loader, DEVICE, \"Final Test Evaluation\")\n",
        "    else:\n",
        "        print(\"No model was saved.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}